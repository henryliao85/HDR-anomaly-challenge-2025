{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Butterfly Classification Pipeline Notebook\n",
    "\n",
    "This notebook runs the full pipeline by importing functions from the repository. It executes:\n",
    "1. Wing segmentation using the pretrained U-Net model\n",
    "2. Data augmentation to balance the dataset\n",
    "3. Fine-tuning the BiO‑CLIP classifier\n",
    "\n",
    "Before running, please ensure you have downloaded the data and U-Net model weights as described in the project summary.\n",
    "\n",
    "Adjust the placeholder paths and parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add repository folders to the Python path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Adjust these relative paths if your repository structure is different\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir, '..', 'remove_bg'))\n",
    "sys.path.append(os.path.join(current_dir, '..', 'augmentation'))\n",
    "sys.path.append(os.path.join(current_dir, '..', 'finetune_bioclip'))\n",
    "\n",
    "# Define common paths (update these paths as needed)\n",
    "PRETRAINED_UNET_MODEL = os.path.join('..', 'models', 'best_unet_model.pth')\n",
    "METADATA_CSV = os.path.join('..', 'data', 'metadata.csv')\n",
    "OUTPUT_WING_IMAGES = os.path.join('..', 'data', 'wing_images')\n",
    "\n",
    "ORIG_IMG_FOLDER = OUTPUT_WING_IMAGES  # Use the segmented wing images\n",
    "OUTPUT_AUG_IMAGES = os.path.join('..', 'data', 'augmented_images')\n",
    "INPUT_CSV_FOR_AUG = METADATA_CSV  \n",
    "OUTPUT_CSV_FOR_AUG = os.path.join('..', 'data', 'augmented_metadata.csv')\n",
    "\n",
    "AUG_MIN_IMAGES_PER_CLASS = 1000\n",
    "AUG_PER_IMAGE_HIGH_COUNT = 1\n",
    "\n",
    "DATA_FOR_FINETUNING = OUTPUT_CSV_FOR_AUG\n",
    "IMG_DIR_FOR_FINETUNING = OUTPUT_AUG_IMAGES\n",
    "CLASSIFIER_SAVE_DIR = os.path.join('..', 'models', 'bioclip_classifier')\n",
    "\n",
    "print('Paths set up successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from the custom modules\n",
    "from select_wings_unet import select_wings\n",
    "from albumentation_augm import augment_dataset\n",
    "from finetune_aug_bg import finetune_model\n",
    "\n",
    "print('Custom modules imported successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wing Segmentation\n",
    "\n",
    "This step uses the pretrained U-Net model to segment the butterfly wings. The function `select_wings` is assumed to perform the following:\n",
    "- Resize input images\n",
    "- Apply the U-Net to generate a segmentation mask\n",
    "- Threshold the mask and remove the background\n",
    "\n",
    "Update the paths if needed before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run wing segmentation\n",
    "select_wings(\n",
    "    model_path=PRETRAINED_UNET_MODEL,\n",
    "    csv_path=METADATA_CSV,\n",
    "    output_folder=OUTPUT_WING_IMAGES\n",
    ")\n",
    "\n",
    "print('Wing segmentation completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation\n",
    "\n",
    "This step augments the segmented wing images to ensure a balanced dataset (at least 1,000 images per class). The function `augment_dataset` should perform the necessary image augmentations and update the metadata CSV accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data augmentation\n",
    "augment_dataset(\n",
    "    orig_img_folder=OUTPUT_WING_IMAGES,\n",
    "    output_img_folder=OUTPUT_AUG_IMAGES,\n",
    "    csv_path=INPUT_CSV_FOR_AUG,\n",
    "    output_csv_path=OUTPUT_CSV_FOR_AUG,\n",
    "    min_images_per_class=AUG_MIN_IMAGES_PER_CLASS,\n",
    "    aug_per_image_high_count=AUG_PER_IMAGE_HIGH_COUNT\n",
    ")\n",
    "\n",
    "print('Data augmentation completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-Tuning BiO-CLIP\n",
    "\n",
    "This step fine-tunes the pre-trained BiO-CLIP model for butterfly subspecies classification. The function `finetune_model` is expected to:\n",
    "- Load the augmented dataset and images\n",
    "- Unfreeze the last two attention blocks of the model with a small learning rate\n",
    "- Train an additional classifier head with a higher learning rate\n",
    "- Save the best model\n",
    "\n",
    "Adjust any additional hyperparameters via keyword arguments as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fine-tuning\n",
    "finetune_model(\n",
    "    data_file=DATA_FOR_FINETUNING,\n",
    "    img_dir=IMG_DIR_FOR_FINETUNING,\n",
    "    clf_save_dir=CLASSIFIER_SAVE_DIR,\n",
    "    # Optionally, you can pass additional hyperparameters here\n",
    "    num_epochs=30,\n",
    "    batch_size=32,\n",
    "    lr_backbone=1e-5,\n",
    "    lr_head=1e-3\n",
    ")\n",
    "\n",
    "print('Fine-tuning completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Completed\n",
    "\n",
    "The notebook has run all the steps of the butterfly classification pipeline:\n",
    "1. Wing segmentation\n",
    "2. Data augmentation\n",
    "3. Fine-tuning of the BiO‑CLIP classifier\n",
    "\n",
    "Check the output folders and saved models to verify that each step was executed correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
